import d2lzh as d2l
from mxnet import autograd, nd
from mxnet.gluon import nn

# äº’ç›¸å…³è¿ç®—
def corr2d(X, K):
    h, w = K.shape
    Y = nd.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()
    return Y

X = nd.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])
K = nd.array([[0, 1], [2, 3]])
out = corr2d(X, K)
print(out)

# ç‰©ä½“è¾¹ç¼˜æ£€æµ‹
X = nd.ones((6, 8))
X[:, 2:6] = 0
print(X)
# ä»ç™½åˆ°é»‘çš„è¾¹ç¼˜å’Œä»é»‘åˆ°ç™½çš„è¾¹ç¼˜åˆ†åˆ«æ£€æµ‹æˆäº†1å’Œ-1
K = nd.array([[1, -1]])
Y = corr2d(X, K)
print(Y)

# é€šè¿‡æ•°æ®å­¦ä¹ æ ¸æ•°ç»„
# æ„é€ ä¸€ä¸ªè¾“å‡ºé€šé“æ•°ä¸º1ï¼ˆå°†åœ¨â€œå¤šè¾“å…¥é€šé“å’Œå¤šè¾“å‡ºé€šé“â€ä¸€èŠ‚ä»‹ç»é€šé“ï¼‰ï¼Œæ ¸æ•°ç»„å½¢çŠ¶æ˜¯(1, 2)çš„äºŒ
# ç»´å·ç§¯å±‚
conv2d = nn.Conv2D(1, kernel_size=(1, 2))
conv2d.initialize()

# äºŒç»´å·ç§¯å±‚ä½¿ç”¨4ç»´è¾“å…¥è¾“å‡ºï¼Œæ ¼å¼ä¸º(æ ·æœ¬, é€šé“, é«˜, å®½)ï¼Œè¿™é‡Œæ‰¹é‡å¤§å°ï¼ˆæ‰¹é‡ä¸­çš„æ ·æœ¬æ•°ï¼‰å’Œé€š
# é“æ•°å‡ä¸º1
X = X.reshape((1, 1, 6, 8))
Y = Y.reshape((1, 1, 6, 7))

for i in range(10):
    with autograd.record():
        Y_hat = conv2d(X)
        l = (Y_hat - Y) ** 2
    l.backward()
    # ç®€å•èµ·è§ï¼Œè¿™é‡Œå¿½ç•¥äº†åå·®
    conv2d.weight.data()[:] -= 3e-2 * conv2d.weight.grad()
    if (i + 1) % 2 == 0:
        print('batch %d, loss %.3f' % (i + 1, l.sum().asscalar()))

K = conv2d.weight.data().reshape((1, 2))
print(K)

# å¡«å……
# (ğ‘›â„âˆ’ğ‘˜â„+ğ‘â„+1)Ã—(ğ‘›ğ‘¤âˆ’ğ‘˜ğ‘¤+ğ‘ğ‘¤+1)
# å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥è®¡ç®—å·ç§¯å±‚ã€‚å®ƒåˆå§‹åŒ–å·ç§¯å±‚æƒé‡ï¼Œå¹¶å¯¹è¾“å…¥å’Œè¾“å‡ºåšç›¸åº”çš„å‡ç»´å’Œé™ç»´
def comp_conv2d(conv2d, X):
    conv2d.initialize()
    # (1, 1)ä»£è¡¨æ‰¹é‡å¤§å°å’Œé€šé“æ•°ï¼ˆâ€œå¤šè¾“å…¥é€šé“å’Œå¤šè¾“å‡ºé€šé“â€ä¸€èŠ‚å°†ä»‹ç»ï¼‰å‡ä¸º1
    X = X.reshape((1, 1) + X.shape)
    print(X.shape)
    Y = conv2d(X)
    print(Y.shape)
    return Y.reshape(Y.shape[2:])  # æ’é™¤ä¸å…³å¿ƒçš„å‰ä¸¤ç»´ï¼šæ‰¹é‡å’Œé€šé“

# æ³¨æ„è¿™é‡Œæ˜¯ä¸¤ä¾§åˆ†åˆ«å¡«å……1è¡Œæˆ–åˆ—ï¼Œæ‰€ä»¥åœ¨ä¸¤ä¾§ä¸€å…±å¡«å……2è¡Œæˆ–åˆ—
# ç»´åº¦ï¼š (8-3+1*2+1) * (8-3+1*2+1)
conv2d = nn.Conv2D(1, kernel_size=3, padding=1)
X = nd.random.uniform(shape=(8, 8))
print(comp_conv2d(conv2d, X).shape)

# ä½¿ç”¨é«˜ä¸º5ã€å®½ä¸º3çš„å·ç§¯æ ¸ã€‚åœ¨é«˜å’Œå®½ä¸¤ä¾§çš„å¡«å……æ•°åˆ†åˆ«ä¸º2å’Œ1
# # ç»´åº¦ï¼š (8-5+2*2+1) * (8-3+1*2+1)
conv2d = nn.Conv2D(1, kernel_size=(5, 3), padding=(2, 1))
print(comp_conv2d(conv2d, X).shape)

# æ­¥å¹…
# âŒŠ(ğ‘›â„âˆ’ğ‘˜â„+ğ‘â„+ğ‘ â„)/ğ‘ â„âŒ‹Ã—âŒŠ(ğ‘›ğ‘¤âˆ’ğ‘˜ğ‘¤+ğ‘ğ‘¤+ğ‘ ğ‘¤)/ğ‘ ğ‘¤âŒ‹
# ä¸‹é¢æˆ‘ä»¬ä»¤é«˜å’Œå®½ä¸Šçš„æ­¥å¹…å‡ä¸º2ï¼Œä»è€Œä½¿è¾“å…¥çš„é«˜å’Œå®½å‡åŠ
# ç»´åº¦ï¼š (8-3+1*2+2)/2 * (8-3+1*2+2)/2
conv2d = nn.Conv2D(1, kernel_size=3, padding=1, strides=2)
print(comp_conv2d(conv2d, X).shape)

# ç»´åº¦ï¼š (8-3+0*2+3)/3 * (8-5+1*2+4)/4
conv2d = nn.Conv2D(1, kernel_size=(3, 5), padding=(0, 1), strides=(3, 4))
print(comp_conv2d(conv2d, X).shape)

# æ± åŒ–å±‚
def pool2d(X, pool_size, mode='max'):
    p_h, p_w = pool_size
    Y = nd.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            if mode == 'max':
                Y[i, j] = X[i: i + p_h, j: j + p_w].max()
            elif mode == 'avg':
                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()
    return Y

X = nd.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])
Y = pool2d(X, (2, 2))
print(Y)
Y = pool2d(X, (2, 2), 'avg')
print(Y)

# å¤šè¾“å…¥é€šé“å’Œå¤šè¾“å‡ºé€šé“
# å¤šè¾“å…¥é€šé“
def corr2d_multi_in(X, K):
    # é¦–å…ˆæ²¿ç€Xå’ŒKçš„ç¬¬0ç»´ï¼ˆé€šé“ç»´ï¼‰éå†ã€‚ç„¶åä½¿ç”¨*å°†ç»“æœåˆ—è¡¨å˜æˆadd_nå‡½æ•°çš„ä½ç½®å‚æ•°
    # ï¼ˆpositional argumentï¼‰æ¥è¿›è¡Œç›¸åŠ 
    return nd.add_n(*[d2l.corr2d(x, k) for x, k in zip(X, K)])

X = nd.array([[[0, 1, 2], [3, 4, 5], [6, 7, 8]],
              [[1, 2, 3], [4, 5, 6], [7, 8, 9]]])
K = nd.array([[[0, 1], [2, 3]], [[1, 2], [3, 4]]])

Y = corr2d_multi_in(X, K)
print(Y)

# å¤šè¾“å‡ºé€šé“
def corr2d_multi_in_out(X, K):
    # å¯¹Kçš„ç¬¬0ç»´éå†ï¼Œæ¯æ¬¡åŒè¾“å…¥Xåšäº’ç›¸å…³è®¡ç®—ã€‚æ‰€æœ‰ç»“æœä½¿ç”¨stackå‡½æ•°åˆå¹¶åœ¨ä¸€èµ·
    return nd.stack(*[corr2d_multi_in(X, k) for k in K])

K = nd.stack(K, K + 1, K + 2)
Y = corr2d_multi_in_out(X, K)
print(Y)

# 1Ã—1 å·ç§¯å±‚
def corr2d_multi_in_out_1x1(X, K):
    c_i, h, w = X.shape
    c_o = K.shape[0]
    X = X.reshape((c_i, h * w))
    K = K.reshape((c_o, c_i))
    Y = nd.dot(K, X)  # å…¨è¿æ¥å±‚çš„çŸ©é˜µä¹˜æ³•
    return Y.reshape((c_o, h, w))

X = nd.random.uniform(shape=(3, 3, 3))
K = nd.random.uniform(shape=(2, 3, 1, 1))

Y1 = corr2d_multi_in_out_1x1(X, K)
Y2 = corr2d_multi_in_out(X, K)
print(Y1)
print(Y2)
print((Y1 - Y2).norm().asscalar() < 1e-6)

# æ± åŒ–å±‚ä¸­çš„å¡«å……å’Œæ­¥å¹…
X = nd.arange(16).reshape((1, 1, 4, 4))
pool2d = nn.MaxPool2D(3)
Y = pool2d(X)
print(Y)

pool2d = nn.MaxPool2D(3, padding=1, strides=2)
Y = pool2d(X)
print(Y)

pool2d = nn.MaxPool2D((2, 3), padding=(1, 2), strides=(2, 3))
Y = pool2d(X)
print(Y)

# æ± åŒ–å±‚ä¸­çš„å¤šé€šé“
# åœ¨å¤„ç†å¤šé€šé“è¾“å…¥æ•°æ®æ—¶ï¼Œæ± åŒ–å±‚å¯¹æ¯ä¸ªè¾“å…¥é€šé“åˆ†åˆ«æ± åŒ–ï¼Œè€Œä¸æ˜¯åƒå·ç§¯å±‚é‚£æ ·å°†å„é€šé“çš„è¾“å…¥æŒ‰é€šé“ç›¸åŠ ã€‚
X = nd.concat(X, X + 1, dim=1)
print(X)

pool2d = nn.MaxPool2D(3, padding=1, strides=2)
Y = pool2d(X)
print(Y)
